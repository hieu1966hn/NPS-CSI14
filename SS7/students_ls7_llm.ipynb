{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup môi trường\n",
    "1. Truy cập [Google AI Studio](https://aistudio.google.com/apikey) và chọn `Create API Key`\n",
    "2. Tạo file `.env` và lưu API key dưới dạng `GOOGLE_API_KEY=\"YOUR_API_KEY\"`\n",
    "3. Sử dụng thư viện `python-dotenv` để quản lý API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM\n",
    "## Tạo LLM với API\n",
    "Sử dụng class `GenerativeModel` và tạo một object LLM với mô hình là `gemini-1.5-flash`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tương tác với LLM\n",
    "Thử tương tác với mô hình bằng phương thức `generate_content` của đối tượng `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"T\\u00f4i l\\u00e0 m\\u1ed9t m\\u00f4 h\\u00ecnh ng\\u00f4n ng\\u1eef l\\u1edbn, \\u0111\\u01b0\\u1ee3c hu\\u1ea5n luy\\u1ec7n b\\u1edfi Google.\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 5,\n",
       "        \"candidates_token_count\": 15,\n",
       "        \"total_token_count\": 49\n",
       "      },\n",
       "      \"model_version\": \"gemini-2.5-flash\"\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Bạn là ai?\"\n",
    "response = model.generate_content(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả sẽ trả về một đối tượng có cấu trúc, và ta quan sát được câu trả lời của mô hình nằm ở phần `result` -> `candidates` -> `content` -> `parts` -> `text`.\n",
    "\n",
    "Để truy cập nhanh câu trả lời, sử dụng trực tiếp thuộc tính `text` của đối tượng `response`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tôi là một mô hình ngôn ngữ lớn, được huấn luyện bởi Google.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thêm ngữ cảnh cho LLM\n",
    "Để hướng dẫn LLM giải quyết một tác vụ cụ thể, ta sử dụng prompt engineering.\n",
    "\n",
    "Bạn là chủ một nhà hàng. Hãy viết hướng dẫn phù hợp để LLM của bạn có thể:\n",
    "1. quảng cáo về nhà hàng\n",
    "2. giới thiệu menu cho khách hàng\n",
    "\n",
    "Với Gemini API, ta có thể đưa hướng dẫn vào tham số `system_instruction` ngay lúc tạo đối tượng `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\",\n",
    "                              system_instruction=\"\"\"\n",
    "                              Bạn tên là VietLot, một trợ lý AI có nhiệm vụ hỗ trợ giải đáp thắc mắc người dùng. Nhà hàng bạn toạ lạc tại địa chỉ 22 Jump Street, New York, US\n",
    "                              \n",
    "                              Các chức năng mà bạn hỗ trợ gồm:\n",
    "                              1. Giới thiệu nhà hàng VietLot: Là một nhà hàng được thành lập vào tháng 9 năm 2025 bởi NTH VÀ NHD. Nhà hàng đã hoạt động được gần 10 ngày và đã được kiểm định và nhận 1 ngôi sao danh giá \"michelin\" từ siêu đầu bếp \"Gordon Ramsay\" và Tập đoàn Michelin cấp.\n",
    "                              2. Giới thiệu về menu nhà hàng gồm các món: Súp bí đỏ, các dạng Salat, Nem cuộn, thịt chó, mắm tôm, vây cá mập, .. và các món hải sản trên biển\n",
    "                              Đối với các câu hỏi ngoài chức năng mà bạn hỗ trợ, trả lời bằng: \"Xin lỗi, tôi không thể trả lời câu hỏi này\"\n",
    "                              \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử lại với prompt đến từ khách hàng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nhà hàng VietLot tọa lạc tại địa chỉ 22 Jump Street, New York, US.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Bạn biết địa chỉ nhà hàng ở đâu không?\"\n",
    "response = model.generate_content(prompt)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thử thách prompt engineer\n",
    "Hãy lần lượt thêm vào hướng dẫn của mô hình các nội dung sau:\n",
    "* Nói chuyện lịch sự hơn với khách hàng\n",
    "* Xử lý các yêu cầu không liên quan đến chức năng của khách hàng\n",
    "\n",
    "Theo dõi cách mô hình thay đổi câu trả lời khi đã chỉnh sửa hướng dẫn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\",\n",
    "                              system_instruction=\"\"\"\n",
    "                              NEW_INSTRUCTION_HERE\n",
    "                              \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ###YOUR_CODE_HERE\n",
    "response = ###YOUR_CODE_HERE\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết nối file dữ liệu với LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đọc file dữ liệu từ `menu.csv` vào DataFrame`menu_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_df = ###YOUR_CODE_HERE \n",
    "menu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cập nhật hướng dẫn với cột `name` trong `menu_df` và thử lại với prompt mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\",\n",
    "                              system_instruction=f\"\"\"\n",
    "                              NEW_INSTRUCTION_WITH_MENU\n",
    "                              \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "prompt = \"Liệt kê các món ăn trong menu\"\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
